{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Algorithm\n",
    "\n",
    "In the following steps we will develop and optimize a TensorFlow based neural network. This code is based on the assignments from the Udacity 'Deep Learning' course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# matlotlib inline plotting\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 2678\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"data/curated_dataset.csv\", sep=\"\\t\", header=0, index_col = 0)\n",
    "print (\"Number of data points:\", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Days_Since_Open</th>\n",
       "      <th>Break_Coming</th>\n",
       "      <th>Overnight_Return</th>\n",
       "      <th>Overnight_VIX</th>\n",
       "      <th>O2O</th>\n",
       "      <th>1d_Ret</th>\n",
       "      <th>2d_Ret</th>\n",
       "      <th>3d_Ret</th>\n",
       "      <th>4d_Ret</th>\n",
       "      <th>5d_Ret</th>\n",
       "      <th>...</th>\n",
       "      <th>126d_Ret</th>\n",
       "      <th>189d_Ret</th>\n",
       "      <th>252d_Ret</th>\n",
       "      <th>1d_VIX</th>\n",
       "      <th>5d_VIX</th>\n",
       "      <th>1d_Rel_Vol</th>\n",
       "      <th>5d_Rel_Vol</th>\n",
       "      <th>1d_PtT</th>\n",
       "      <th>1d_VIX_PtT</th>\n",
       "      <th>Intraday_Increase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001138</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.011775</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>-0.002669</td>\n",
       "      <td>0.003814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054196</td>\n",
       "      <td>0.044752</td>\n",
       "      <td>0.152477</td>\n",
       "      <td>-0.054198</td>\n",
       "      <td>-0.068421</td>\n",
       "      <td>0.150982</td>\n",
       "      <td>-0.002956</td>\n",
       "      <td>0.009513</td>\n",
       "      <td>0.105180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>-0.015267</td>\n",
       "      <td>0.007367</td>\n",
       "      <td>0.006444</td>\n",
       "      <td>-0.002199</td>\n",
       "      <td>-0.007923</td>\n",
       "      <td>-0.001475</td>\n",
       "      <td>0.009426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046503</td>\n",
       "      <td>0.050294</td>\n",
       "      <td>0.147818</td>\n",
       "      <td>-0.096552</td>\n",
       "      <td>-0.177136</td>\n",
       "      <td>-0.003421</td>\n",
       "      <td>-0.000493</td>\n",
       "      <td>0.009094</td>\n",
       "      <td>0.135299</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.078621</td>\n",
       "      <td>-0.005791</td>\n",
       "      <td>-0.008588</td>\n",
       "      <td>-0.014275</td>\n",
       "      <td>-0.007868</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>0.003263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044326</td>\n",
       "      <td>0.041296</td>\n",
       "      <td>0.111197</td>\n",
       "      <td>0.179821</td>\n",
       "      <td>-0.066323</td>\n",
       "      <td>-0.062535</td>\n",
       "      <td>-0.016959</td>\n",
       "      <td>0.006272</td>\n",
       "      <td>0.098703</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.002841</td>\n",
       "      <td>0.078926</td>\n",
       "      <td>-0.006787</td>\n",
       "      <td>-0.005737</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.011651</td>\n",
       "      <td>0.011954</td>\n",
       "      <td>0.011935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062659</td>\n",
       "      <td>0.048637</td>\n",
       "      <td>0.120301</td>\n",
       "      <td>0.022463</td>\n",
       "      <td>-0.200390</td>\n",
       "      <td>-0.022102</td>\n",
       "      <td>-0.021904</td>\n",
       "      <td>0.004509</td>\n",
       "      <td>0.053520</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.001787</td>\n",
       "      <td>-0.001664</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.017488</td>\n",
       "      <td>0.017792</td>\n",
       "      <td>0.017773</td>\n",
       "      <td>0.013934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069373</td>\n",
       "      <td>0.067784</td>\n",
       "      <td>0.122976</td>\n",
       "      <td>-0.096241</td>\n",
       "      <td>-0.262577</td>\n",
       "      <td>-0.054481</td>\n",
       "      <td>0.101086</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.128296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003615</td>\n",
       "      <td>0.006767</td>\n",
       "      <td>0.012291</td>\n",
       "      <td>0.010917</td>\n",
       "      <td>0.011220</td>\n",
       "      <td>0.011201</td>\n",
       "      <td>0.007386</td>\n",
       "      <td>0.017570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062066</td>\n",
       "      <td>0.070242</td>\n",
       "      <td>0.113438</td>\n",
       "      <td>-0.164573</td>\n",
       "      <td>-0.266814</td>\n",
       "      <td>0.010656</td>\n",
       "      <td>0.093209</td>\n",
       "      <td>0.011858</td>\n",
       "      <td>0.188227</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002253</td>\n",
       "      <td>-0.053392</td>\n",
       "      <td>-0.000634</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>-0.003493</td>\n",
       "      <td>0.006581</td>\n",
       "      <td>0.005990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043887</td>\n",
       "      <td>0.066919</td>\n",
       "      <td>0.087846</td>\n",
       "      <td>0.025113</td>\n",
       "      <td>-0.108123</td>\n",
       "      <td>-0.174317</td>\n",
       "      <td>0.099463</td>\n",
       "      <td>0.005427</td>\n",
       "      <td>0.090615</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003188</td>\n",
       "      <td>-0.035415</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.003791</td>\n",
       "      <td>0.006280</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>-0.009226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042659</td>\n",
       "      <td>0.047618</td>\n",
       "      <td>0.092486</td>\n",
       "      <td>0.010410</td>\n",
       "      <td>0.024406</td>\n",
       "      <td>-0.218716</td>\n",
       "      <td>0.178595</td>\n",
       "      <td>0.008265</td>\n",
       "      <td>0.088686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>-0.014964</td>\n",
       "      <td>-0.001160</td>\n",
       "      <td>-0.003772</td>\n",
       "      <td>0.006299</td>\n",
       "      <td>0.005708</td>\n",
       "      <td>-0.009208</td>\n",
       "      <td>0.005334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043707</td>\n",
       "      <td>0.031880</td>\n",
       "      <td>0.074847</td>\n",
       "      <td>-0.057055</td>\n",
       "      <td>-0.121714</td>\n",
       "      <td>0.320440</td>\n",
       "      <td>0.240760</td>\n",
       "      <td>0.007131</td>\n",
       "      <td>0.114537</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000363</td>\n",
       "      <td>0.006748</td>\n",
       "      <td>0.009937</td>\n",
       "      <td>0.010109</td>\n",
       "      <td>0.009516</td>\n",
       "      <td>-0.005456</td>\n",
       "      <td>0.009141</td>\n",
       "      <td>-0.015605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052274</td>\n",
       "      <td>0.050822</td>\n",
       "      <td>0.076154</td>\n",
       "      <td>-0.101433</td>\n",
       "      <td>0.302958</td>\n",
       "      <td>-0.159209</td>\n",
       "      <td>0.210159</td>\n",
       "      <td>0.013551</td>\n",
       "      <td>0.135979</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000193</td>\n",
       "      <td>-0.009372</td>\n",
       "      <td>-0.001175</td>\n",
       "      <td>-0.000588</td>\n",
       "      <td>-0.015410</td>\n",
       "      <td>-0.000959</td>\n",
       "      <td>-0.025457</td>\n",
       "      <td>-0.027624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048613</td>\n",
       "      <td>0.051352</td>\n",
       "      <td>0.074658</td>\n",
       "      <td>0.016246</td>\n",
       "      <td>0.519263</td>\n",
       "      <td>-0.090453</td>\n",
       "      <td>0.239457</td>\n",
       "      <td>0.010076</td>\n",
       "      <td>0.100643</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>-0.012325</td>\n",
       "      <td>-0.010514</td>\n",
       "      <td>-0.014831</td>\n",
       "      <td>-0.000371</td>\n",
       "      <td>-0.024884</td>\n",
       "      <td>-0.027052</td>\n",
       "      <td>-0.027194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055106</td>\n",
       "      <td>0.056973</td>\n",
       "      <td>0.089087</td>\n",
       "      <td>0.177441</td>\n",
       "      <td>0.485025</td>\n",
       "      <td>0.083377</td>\n",
       "      <td>0.217709</td>\n",
       "      <td>0.014120</td>\n",
       "      <td>0.185634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.003969</td>\n",
       "      <td>0.054090</td>\n",
       "      <td>0.013961</td>\n",
       "      <td>0.014677</td>\n",
       "      <td>-0.010205</td>\n",
       "      <td>-0.012405</td>\n",
       "      <td>-0.012550</td>\n",
       "      <td>-0.009606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069022</td>\n",
       "      <td>0.052046</td>\n",
       "      <td>0.100961</td>\n",
       "      <td>-0.133714</td>\n",
       "      <td>0.265442</td>\n",
       "      <td>0.089148</td>\n",
       "      <td>0.170459</td>\n",
       "      <td>0.020645</td>\n",
       "      <td>0.325871</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.003266</td>\n",
       "      <td>0.150286</td>\n",
       "      <td>-0.022231</td>\n",
       "      <td>-0.024522</td>\n",
       "      <td>-0.026691</td>\n",
       "      <td>-0.026833</td>\n",
       "      <td>-0.023931</td>\n",
       "      <td>-0.019831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052231</td>\n",
       "      <td>0.039163</td>\n",
       "      <td>0.089905</td>\n",
       "      <td>0.398881</td>\n",
       "      <td>0.298220</td>\n",
       "      <td>0.246563</td>\n",
       "      <td>0.102898</td>\n",
       "      <td>0.019209</td>\n",
       "      <td>0.334444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.005602</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>-0.006267</td>\n",
       "      <td>-0.002223</td>\n",
       "      <td>-0.002369</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.004809</td>\n",
       "      <td>0.004767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096368</td>\n",
       "      <td>0.057041</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>0.047739</td>\n",
       "      <td>-0.067809</td>\n",
       "      <td>0.125359</td>\n",
       "      <td>0.044724</td>\n",
       "      <td>0.003414</td>\n",
       "      <td>0.078351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001555</td>\n",
       "      <td>-0.016750</td>\n",
       "      <td>-0.001103</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>0.007048</td>\n",
       "      <td>0.007006</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098982</td>\n",
       "      <td>0.052521</td>\n",
       "      <td>0.110058</td>\n",
       "      <td>-0.006656</td>\n",
       "      <td>-0.089939</td>\n",
       "      <td>-0.030634</td>\n",
       "      <td>0.045834</td>\n",
       "      <td>0.004026</td>\n",
       "      <td>0.057071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000599</td>\n",
       "      <td>-0.010815</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>0.002982</td>\n",
       "      <td>0.007195</td>\n",
       "      <td>0.007154</td>\n",
       "      <td>0.004761</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104696</td>\n",
       "      <td>0.045317</td>\n",
       "      <td>0.138069</td>\n",
       "      <td>0.003339</td>\n",
       "      <td>-0.071097</td>\n",
       "      <td>0.040295</td>\n",
       "      <td>0.019176</td>\n",
       "      <td>0.005252</td>\n",
       "      <td>0.088380</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.036728</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>0.001774</td>\n",
       "      <td>-0.000183</td>\n",
       "      <td>0.005044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089032</td>\n",
       "      <td>0.063602</td>\n",
       "      <td>0.117291</td>\n",
       "      <td>-0.111276</td>\n",
       "      <td>-0.122344</td>\n",
       "      <td>-0.035539</td>\n",
       "      <td>-0.048334</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>0.157171</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003054</td>\n",
       "      <td>-0.000742</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.002417</td>\n",
       "      <td>-0.004366</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>-0.000741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085435</td>\n",
       "      <td>0.043929</td>\n",
       "      <td>0.113913</td>\n",
       "      <td>0.004471</td>\n",
       "      <td>-0.011005</td>\n",
       "      <td>0.062502</td>\n",
       "      <td>-0.037720</td>\n",
       "      <td>0.007586</td>\n",
       "      <td>0.122034</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>-0.026080</td>\n",
       "      <td>-0.001026</td>\n",
       "      <td>-0.002376</td>\n",
       "      <td>-0.004325</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>-0.000700</td>\n",
       "      <td>-0.002064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089069</td>\n",
       "      <td>0.032493</td>\n",
       "      <td>0.134337</td>\n",
       "      <td>0.022866</td>\n",
       "      <td>-0.002230</td>\n",
       "      <td>0.258270</td>\n",
       "      <td>-0.076330</td>\n",
       "      <td>0.005727</td>\n",
       "      <td>0.103163</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001176</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>-0.002703</td>\n",
       "      <td>-0.001954</td>\n",
       "      <td>0.003264</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>-0.004929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095482</td>\n",
       "      <td>0.046005</td>\n",
       "      <td>0.103408</td>\n",
       "      <td>0.013910</td>\n",
       "      <td>0.059774</td>\n",
       "      <td>-0.007223</td>\n",
       "      <td>-0.116234</td>\n",
       "      <td>0.005446</td>\n",
       "      <td>0.069071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004267</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>-0.002981</td>\n",
       "      <td>-0.001035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102120</td>\n",
       "      <td>0.043189</td>\n",
       "      <td>0.096291</td>\n",
       "      <td>-0.052015</td>\n",
       "      <td>0.054605</td>\n",
       "      <td>-0.150567</td>\n",
       "      <td>-0.114401</td>\n",
       "      <td>0.006110</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.032234</td>\n",
       "      <td>-0.002257</td>\n",
       "      <td>-0.001579</td>\n",
       "      <td>-0.002942</td>\n",
       "      <td>-0.008167</td>\n",
       "      <td>-0.006231</td>\n",
       "      <td>-0.006791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122558</td>\n",
       "      <td>0.038380</td>\n",
       "      <td>0.091253</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.203704</td>\n",
       "      <td>0.120028</td>\n",
       "      <td>-0.110269</td>\n",
       "      <td>0.012684</td>\n",
       "      <td>0.205958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>-0.006603</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>-0.006598</td>\n",
       "      <td>-0.004659</td>\n",
       "      <td>-0.005220</td>\n",
       "      <td>-0.006653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115202</td>\n",
       "      <td>0.039887</td>\n",
       "      <td>0.119536</td>\n",
       "      <td>0.013383</td>\n",
       "      <td>0.192476</td>\n",
       "      <td>-0.014510</td>\n",
       "      <td>-0.129540</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>0.058716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000988</td>\n",
       "      <td>0.012639</td>\n",
       "      <td>-0.005400</td>\n",
       "      <td>-0.005240</td>\n",
       "      <td>-0.003299</td>\n",
       "      <td>-0.003860</td>\n",
       "      <td>-0.005295</td>\n",
       "      <td>-0.003107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114639</td>\n",
       "      <td>0.042581</td>\n",
       "      <td>0.164826</td>\n",
       "      <td>0.086430</td>\n",
       "      <td>0.103363</td>\n",
       "      <td>0.031850</td>\n",
       "      <td>-0.109254</td>\n",
       "      <td>0.007068</td>\n",
       "      <td>0.130784</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000828</td>\n",
       "      <td>0.025848</td>\n",
       "      <td>-0.001243</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.004017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133226</td>\n",
       "      <td>0.046779</td>\n",
       "      <td>0.155128</td>\n",
       "      <td>0.008965</td>\n",
       "      <td>-0.020570</td>\n",
       "      <td>-0.030742</td>\n",
       "      <td>-0.090006</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>0.058704</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>-0.009780</td>\n",
       "      <td>0.002856</td>\n",
       "      <td>-0.000563</td>\n",
       "      <td>-0.002003</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.002061</td>\n",
       "      <td>-0.003429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136040</td>\n",
       "      <td>0.048721</td>\n",
       "      <td>0.107439</td>\n",
       "      <td>0.082011</td>\n",
       "      <td>0.038950</td>\n",
       "      <td>-0.143437</td>\n",
       "      <td>-0.078570</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>0.087097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001049</td>\n",
       "      <td>0.104938</td>\n",
       "      <td>-0.001218</td>\n",
       "      <td>-0.001440</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>-0.002867</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122524</td>\n",
       "      <td>0.048134</td>\n",
       "      <td>0.072770</td>\n",
       "      <td>-0.007874</td>\n",
       "      <td>-0.018182</td>\n",
       "      <td>-0.048225</td>\n",
       "      <td>-0.061536</td>\n",
       "      <td>0.004519</td>\n",
       "      <td>0.082573</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.001271</td>\n",
       "      <td>0.020997</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.004072</td>\n",
       "      <td>-0.001429</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140391</td>\n",
       "      <td>0.066610</td>\n",
       "      <td>0.051649</td>\n",
       "      <td>-0.062346</td>\n",
       "      <td>-0.021404</td>\n",
       "      <td>0.042464</td>\n",
       "      <td>-0.072460</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.093948</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000147</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>-0.003621</td>\n",
       "      <td>-0.000838</td>\n",
       "      <td>-0.001633</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137859</td>\n",
       "      <td>0.062844</td>\n",
       "      <td>0.040679</td>\n",
       "      <td>-0.035601</td>\n",
       "      <td>0.011618</td>\n",
       "      <td>0.067478</td>\n",
       "      <td>-0.066361</td>\n",
       "      <td>0.006688</td>\n",
       "      <td>0.126817</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5653</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>-0.030778</td>\n",
       "      <td>-0.008358</td>\n",
       "      <td>-0.008337</td>\n",
       "      <td>-0.008782</td>\n",
       "      <td>-0.008515</td>\n",
       "      <td>-0.011417</td>\n",
       "      <td>-0.016471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055481</td>\n",
       "      <td>-0.010843</td>\n",
       "      <td>-0.005931</td>\n",
       "      <td>0.077597</td>\n",
       "      <td>0.036725</td>\n",
       "      <td>-0.031070</td>\n",
       "      <td>-0.100699</td>\n",
       "      <td>0.014380</td>\n",
       "      <td>0.114114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5654</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.006258</td>\n",
       "      <td>-0.000246</td>\n",
       "      <td>-0.000448</td>\n",
       "      <td>-0.000179</td>\n",
       "      <td>-0.003106</td>\n",
       "      <td>-0.008202</td>\n",
       "      <td>-0.002058</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049670</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>-0.002861</td>\n",
       "      <td>-0.017824</td>\n",
       "      <td>-0.055556</td>\n",
       "      <td>0.174395</td>\n",
       "      <td>-0.135747</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>0.073604</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5657</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>-0.027406</td>\n",
       "      <td>-0.004891</td>\n",
       "      <td>-0.005113</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>-0.007341</td>\n",
       "      <td>-0.001071</td>\n",
       "      <td>-0.001606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029385</td>\n",
       "      <td>-0.005577</td>\n",
       "      <td>-0.002429</td>\n",
       "      <td>-0.011439</td>\n",
       "      <td>-0.094319</td>\n",
       "      <td>-0.060616</td>\n",
       "      <td>-0.145316</td>\n",
       "      <td>0.007733</td>\n",
       "      <td>0.073512</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5658</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>-0.006623</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006195</td>\n",
       "      <td>-0.002240</td>\n",
       "      <td>0.004062</td>\n",
       "      <td>0.003525</td>\n",
       "      <td>0.024948</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023889</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>-0.018322</td>\n",
       "      <td>-0.304147</td>\n",
       "      <td>-0.203576</td>\n",
       "      <td>-0.069716</td>\n",
       "      <td>0.007224</td>\n",
       "      <td>0.074298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5659</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>-0.024823</td>\n",
       "      <td>-0.008361</td>\n",
       "      <td>-0.008384</td>\n",
       "      <td>-0.002120</td>\n",
       "      <td>-0.002655</td>\n",
       "      <td>0.018637</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028698</td>\n",
       "      <td>-0.004187</td>\n",
       "      <td>-0.002832</td>\n",
       "      <td>-0.003534</td>\n",
       "      <td>-0.172616</td>\n",
       "      <td>-0.188452</td>\n",
       "      <td>0.002549</td>\n",
       "      <td>0.011982</td>\n",
       "      <td>0.069420</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5660</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>-0.028269</td>\n",
       "      <td>0.006204</td>\n",
       "      <td>0.006316</td>\n",
       "      <td>0.005778</td>\n",
       "      <td>0.027249</td>\n",
       "      <td>0.011463</td>\n",
       "      <td>0.011963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018076</td>\n",
       "      <td>0.006182</td>\n",
       "      <td>0.020460</td>\n",
       "      <td>-0.023015</td>\n",
       "      <td>-0.086606</td>\n",
       "      <td>-0.182802</td>\n",
       "      <td>0.098977</td>\n",
       "      <td>0.010501</td>\n",
       "      <td>0.077937</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5661</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.031070</td>\n",
       "      <td>-0.000402</td>\n",
       "      <td>-0.000535</td>\n",
       "      <td>0.020801</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>-0.009790</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027543</td>\n",
       "      <td>-0.001315</td>\n",
       "      <td>0.012016</td>\n",
       "      <td>-0.041368</td>\n",
       "      <td>0.053972</td>\n",
       "      <td>-0.197065</td>\n",
       "      <td>0.179804</td>\n",
       "      <td>0.010376</td>\n",
       "      <td>0.090006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5663</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>-0.093842</td>\n",
       "      <td>-0.014630</td>\n",
       "      <td>-0.015367</td>\n",
       "      <td>-0.014880</td>\n",
       "      <td>-0.029968</td>\n",
       "      <td>-0.045826</td>\n",
       "      <td>-0.047028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048598</td>\n",
       "      <td>-0.005686</td>\n",
       "      <td>-0.007619</td>\n",
       "      <td>0.167237</td>\n",
       "      <td>0.746159</td>\n",
       "      <td>-0.006670</td>\n",
       "      <td>0.139560</td>\n",
       "      <td>0.022157</td>\n",
       "      <td>0.197557</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5664</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000247</td>\n",
       "      <td>0.154523</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>-0.014829</td>\n",
       "      <td>-0.030935</td>\n",
       "      <td>-0.032155</td>\n",
       "      <td>-0.040013</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033624</td>\n",
       "      <td>-0.000157</td>\n",
       "      <td>0.009923</td>\n",
       "      <td>0.100054</td>\n",
       "      <td>0.522710</td>\n",
       "      <td>0.309400</td>\n",
       "      <td>0.061666</td>\n",
       "      <td>0.024682</td>\n",
       "      <td>0.180745</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5670</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>-0.007311</td>\n",
       "      <td>-0.000682</td>\n",
       "      <td>-0.000555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005350</td>\n",
       "      <td>-0.005012</td>\n",
       "      <td>-0.001875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023594</td>\n",
       "      <td>0.049080</td>\n",
       "      <td>0.039168</td>\n",
       "      <td>-0.080657</td>\n",
       "      <td>-0.151620</td>\n",
       "      <td>-0.131032</td>\n",
       "      <td>0.033622</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5671</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>-0.112771</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>-0.004798</td>\n",
       "      <td>-0.004460</td>\n",
       "      <td>-0.001321</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027619</td>\n",
       "      <td>0.057786</td>\n",
       "      <td>0.046265</td>\n",
       "      <td>-0.066248</td>\n",
       "      <td>-0.094046</td>\n",
       "      <td>-0.145498</td>\n",
       "      <td>0.058090</td>\n",
       "      <td>0.005527</td>\n",
       "      <td>0.089279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5672</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000299</td>\n",
       "      <td>-0.027894</td>\n",
       "      <td>-0.005647</td>\n",
       "      <td>-0.005350</td>\n",
       "      <td>-0.005012</td>\n",
       "      <td>-0.001875</td>\n",
       "      <td>0.003276</td>\n",
       "      <td>0.002460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034419</td>\n",
       "      <td>0.050703</td>\n",
       "      <td>0.044077</td>\n",
       "      <td>0.076577</td>\n",
       "      <td>-0.136665</td>\n",
       "      <td>-0.281686</td>\n",
       "      <td>0.087666</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.053398</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5674</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.076803</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>0.008330</td>\n",
       "      <td>0.007510</td>\n",
       "      <td>0.009562</td>\n",
       "      <td>0.015089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026306</td>\n",
       "      <td>0.061351</td>\n",
       "      <td>0.046026</td>\n",
       "      <td>-0.120606</td>\n",
       "      <td>-0.229003</td>\n",
       "      <td>0.034277</td>\n",
       "      <td>-0.024682</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>0.043863</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5676</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.038566</td>\n",
       "      <td>-0.000749</td>\n",
       "      <td>-0.000813</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.006704</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011720</td>\n",
       "      <td>0.043761</td>\n",
       "      <td>0.041712</td>\n",
       "      <td>-0.110175</td>\n",
       "      <td>-0.089341</td>\n",
       "      <td>-0.022699</td>\n",
       "      <td>0.021934</td>\n",
       "      <td>0.006314</td>\n",
       "      <td>0.095661</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.107553</td>\n",
       "      <td>-0.006894</td>\n",
       "      <td>-0.006766</td>\n",
       "      <td>-0.004250</td>\n",
       "      <td>-0.006447</td>\n",
       "      <td>-0.001807</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>0.037204</td>\n",
       "      <td>0.031278</td>\n",
       "      <td>0.148508</td>\n",
       "      <td>0.011614</td>\n",
       "      <td>0.225758</td>\n",
       "      <td>0.019406</td>\n",
       "      <td>0.010376</td>\n",
       "      <td>0.052099</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5680</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.115892</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.004992</td>\n",
       "      <td>0.008747</td>\n",
       "      <td>0.004841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020896</td>\n",
       "      <td>0.048678</td>\n",
       "      <td>0.029401</td>\n",
       "      <td>-0.112138</td>\n",
       "      <td>-0.103856</td>\n",
       "      <td>0.043711</td>\n",
       "      <td>-0.035383</td>\n",
       "      <td>0.008617</td>\n",
       "      <td>0.044689</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5681</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>-0.095502</td>\n",
       "      <td>-0.002099</td>\n",
       "      <td>-0.002206</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.006199</td>\n",
       "      <td>0.002302</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020212</td>\n",
       "      <td>0.045090</td>\n",
       "      <td>0.020928</td>\n",
       "      <td>0.138149</td>\n",
       "      <td>0.025268</td>\n",
       "      <td>-0.046323</td>\n",
       "      <td>0.003573</td>\n",
       "      <td>0.005939</td>\n",
       "      <td>0.019814</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5682</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.126928</td>\n",
       "      <td>0.004691</td>\n",
       "      <td>0.004669</td>\n",
       "      <td>0.008423</td>\n",
       "      <td>0.004518</td>\n",
       "      <td>0.005318</td>\n",
       "      <td>-0.000492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018298</td>\n",
       "      <td>0.049920</td>\n",
       "      <td>0.027531</td>\n",
       "      <td>-0.108750</td>\n",
       "      <td>-0.041022</td>\n",
       "      <td>-0.099951</td>\n",
       "      <td>0.006332</td>\n",
       "      <td>0.007149</td>\n",
       "      <td>0.208617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5684</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>-0.043399</td>\n",
       "      <td>-0.003830</td>\n",
       "      <td>-0.003873</td>\n",
       "      <td>-0.003079</td>\n",
       "      <td>-0.008841</td>\n",
       "      <td>-0.006566</td>\n",
       "      <td>-0.002692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003707</td>\n",
       "      <td>0.028774</td>\n",
       "      <td>0.037883</td>\n",
       "      <td>0.017413</td>\n",
       "      <td>0.025063</td>\n",
       "      <td>-0.033768</td>\n",
       "      <td>-0.045316</td>\n",
       "      <td>0.005023</td>\n",
       "      <td>0.052550</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5686</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>0.125711</td>\n",
       "      <td>-0.005972</td>\n",
       "      <td>-0.005780</td>\n",
       "      <td>-0.003497</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>-0.013278</td>\n",
       "      <td>-0.014890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>0.023334</td>\n",
       "      <td>0.033789</td>\n",
       "      <td>0.064560</td>\n",
       "      <td>0.170858</td>\n",
       "      <td>0.018892</td>\n",
       "      <td>-0.041025</td>\n",
       "      <td>0.011614</td>\n",
       "      <td>0.316790</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5687</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>-0.154001</td>\n",
       "      <td>0.002403</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>0.006203</td>\n",
       "      <td>-0.007542</td>\n",
       "      <td>-0.009163</td>\n",
       "      <td>-0.001176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011344</td>\n",
       "      <td>0.029328</td>\n",
       "      <td>0.042956</td>\n",
       "      <td>0.004730</td>\n",
       "      <td>0.011565</td>\n",
       "      <td>-0.102444</td>\n",
       "      <td>-0.073126</td>\n",
       "      <td>0.006622</td>\n",
       "      <td>0.090361</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5689</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>-0.059524</td>\n",
       "      <td>-0.013428</td>\n",
       "      <td>-0.013661</td>\n",
       "      <td>-0.015272</td>\n",
       "      <td>-0.007334</td>\n",
       "      <td>-0.012927</td>\n",
       "      <td>-0.018042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>0.026193</td>\n",
       "      <td>0.047093</td>\n",
       "      <td>0.147376</td>\n",
       "      <td>0.215537</td>\n",
       "      <td>0.129904</td>\n",
       "      <td>-0.013984</td>\n",
       "      <td>0.013670</td>\n",
       "      <td>0.097143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5690</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>0.117182</td>\n",
       "      <td>-0.001760</td>\n",
       "      <td>-0.001633</td>\n",
       "      <td>0.006415</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>-0.004442</td>\n",
       "      <td>-0.003873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022950</td>\n",
       "      <td>0.038043</td>\n",
       "      <td>0.064091</td>\n",
       "      <td>0.028846</td>\n",
       "      <td>0.038060</td>\n",
       "      <td>0.033386</td>\n",
       "      <td>-0.045985</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>0.169887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5691</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008104</td>\n",
       "      <td>0.008061</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>-0.002813</td>\n",
       "      <td>-0.002243</td>\n",
       "      <td>0.002616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025426</td>\n",
       "      <td>0.050373</td>\n",
       "      <td>0.069386</td>\n",
       "      <td>-0.080272</td>\n",
       "      <td>-0.053221</td>\n",
       "      <td>-0.122932</td>\n",
       "      <td>-0.037410</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.115911</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5693</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>0.013053</td>\n",
       "      <td>-0.005288</td>\n",
       "      <td>-0.005182</td>\n",
       "      <td>-0.004614</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031086</td>\n",
       "      <td>0.054952</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>0.050267</td>\n",
       "      <td>-0.031601</td>\n",
       "      <td>0.260339</td>\n",
       "      <td>-0.107507</td>\n",
       "      <td>0.014166</td>\n",
       "      <td>0.131123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5695</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.020896</td>\n",
       "      <td>0.004891</td>\n",
       "      <td>0.004870</td>\n",
       "      <td>0.004977</td>\n",
       "      <td>0.007656</td>\n",
       "      <td>-0.000529</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036137</td>\n",
       "      <td>0.055745</td>\n",
       "      <td>0.094050</td>\n",
       "      <td>-0.061625</td>\n",
       "      <td>-0.019034</td>\n",
       "      <td>0.079439</td>\n",
       "      <td>-0.086152</td>\n",
       "      <td>0.006746</td>\n",
       "      <td>0.054446</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5699</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>-0.045865</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.003651</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>-0.016517</td>\n",
       "      <td>-0.019149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053034</td>\n",
       "      <td>0.076361</td>\n",
       "      <td>0.056092</td>\n",
       "      <td>-0.026354</td>\n",
       "      <td>0.253534</td>\n",
       "      <td>-0.023841</td>\n",
       "      <td>0.065915</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>0.086990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>-0.003721</td>\n",
       "      <td>-0.002656</td>\n",
       "      <td>-0.002676</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>-0.001869</td>\n",
       "      <td>0.004199</td>\n",
       "      <td>0.007672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071387</td>\n",
       "      <td>0.086817</td>\n",
       "      <td>0.070791</td>\n",
       "      <td>0.013195</td>\n",
       "      <td>0.043689</td>\n",
       "      <td>-0.010936</td>\n",
       "      <td>0.061150</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.058934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.004879</td>\n",
       "      <td>0.004962</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.006894</td>\n",
       "      <td>0.010376</td>\n",
       "      <td>0.018597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075581</td>\n",
       "      <td>0.087398</td>\n",
       "      <td>0.072159</td>\n",
       "      <td>-0.003756</td>\n",
       "      <td>-0.050134</td>\n",
       "      <td>0.008291</td>\n",
       "      <td>0.092981</td>\n",
       "      <td>0.005532</td>\n",
       "      <td>0.046336</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.016933</td>\n",
       "      <td>0.006058</td>\n",
       "      <td>0.006079</td>\n",
       "      <td>0.009559</td>\n",
       "      <td>0.017773</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.020425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071983</td>\n",
       "      <td>0.084585</td>\n",
       "      <td>0.088261</td>\n",
       "      <td>0.069416</td>\n",
       "      <td>-0.083621</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.125499</td>\n",
       "      <td>0.008643</td>\n",
       "      <td>0.115310</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2678 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Days_Since_Open  Break_Coming  Overnight_Return  Overnight_VIX  \\\n",
       "0                 1.0             0         -0.001138       0.011299   \n",
       "1                 1.0             0          0.000889      -0.015267   \n",
       "2                 1.0             0         -0.000028      -0.078621   \n",
       "3                 3.0             0         -0.002841       0.078926   \n",
       "4                 1.0             1         -0.001787      -0.001664   \n",
       "5                 1.0             0          0.003615       0.006767   \n",
       "6                 1.0             0          0.002253      -0.053392   \n",
       "7                 1.0             0          0.003188      -0.035415   \n",
       "8                 3.0             0          0.002258      -0.014964   \n",
       "9                 1.0             1         -0.000363       0.006748   \n",
       "10                1.0             0         -0.000193      -0.009372   \n",
       "11                1.0             0          0.000395      -0.012325   \n",
       "12                1.0             0         -0.003969       0.054090   \n",
       "13                3.0             0         -0.003266       0.150286   \n",
       "14                1.0             1         -0.005602       0.000799   \n",
       "15                1.0             0         -0.001555      -0.016750   \n",
       "16                1.0             0         -0.000599      -0.010815   \n",
       "17                4.0             0          0.000748       0.036728   \n",
       "18                1.0             1          0.003054      -0.000742   \n",
       "19                1.0             0          0.000175      -0.026080   \n",
       "20                1.0             0         -0.001176       0.001524   \n",
       "21                1.0             0         -0.000427       0.000000   \n",
       "22                3.0             0          0.000530       0.032234   \n",
       "23                1.0             1          0.001211      -0.006603   \n",
       "24                1.0             0         -0.000988       0.012639   \n",
       "25                1.0             0         -0.000828       0.025848   \n",
       "26                1.0             0          0.002369      -0.009780   \n",
       "27                3.0             0         -0.001049       0.104938   \n",
       "28                1.0             1         -0.001271       0.020997   \n",
       "29                1.0             0         -0.000147       0.000820   \n",
       "...               ...           ...               ...            ...   \n",
       "5653              1.0             0          0.000181      -0.030778   \n",
       "5654              3.0             0          0.000202       0.006258   \n",
       "5657              1.0             0          0.000134      -0.027406   \n",
       "5658              1.0             0         -0.000089      -0.006623   \n",
       "5659              3.0             0          0.000045      -0.024823   \n",
       "5660              1.0             1          0.000022      -0.028269   \n",
       "5661              1.0             0          0.000134       0.031070   \n",
       "5663              1.0             0          0.000501      -0.093842   \n",
       "5664              4.0             0         -0.000247       0.154523   \n",
       "5670              1.0             0          0.000064      -0.007311   \n",
       "5671              1.0             0          0.000192      -0.112771   \n",
       "5672              1.0             0         -0.000299      -0.027894   \n",
       "5674              1.0             1         -0.000021       0.076803   \n",
       "5676              1.0             0          0.000064       0.038566   \n",
       "5679              1.0             1         -0.000086      -0.107553   \n",
       "5680              1.0             0          0.000043       0.115892   \n",
       "5681              1.0             0          0.000129      -0.095502   \n",
       "5682              1.0             0          0.000021       0.126928   \n",
       "5684              1.0             1          0.000043      -0.043399   \n",
       "5686              1.0             0         -0.000086       0.125711   \n",
       "5687              1.0             0          0.000107      -0.154001   \n",
       "5689              1.0             1          0.000151      -0.059524   \n",
       "5690              1.0             0         -0.000085       0.117182   \n",
       "5691              1.0             0          0.000042       0.000000   \n",
       "5693              1.0             1         -0.000106       0.013053   \n",
       "5695              1.0             0          0.000021      -0.020896   \n",
       "5699              1.0             0          0.000085      -0.045865   \n",
       "5703              1.0             1         -0.000062      -0.003721   \n",
       "5704              1.0             0         -0.000083       0.001885   \n",
       "5706              1.0             0         -0.000021       0.016933   \n",
       "\n",
       "           O2O    1d_Ret    2d_Ret    3d_Ret    4d_Ret    5d_Ret  \\\n",
       "0     0.003261  0.005296  0.011775  0.003086 -0.002669  0.003814   \n",
       "1     0.007367  0.006444 -0.002199 -0.007923 -0.001475  0.009426   \n",
       "2    -0.005791 -0.008588 -0.014275 -0.007868  0.002963  0.003263   \n",
       "3    -0.006787 -0.005737  0.000726  0.011651  0.011954  0.011935   \n",
       "4     0.001082  0.006500  0.017488  0.017792  0.017773  0.013934   \n",
       "5     0.012291  0.010917  0.011220  0.011201  0.007386  0.017570   \n",
       "6    -0.000634  0.000299  0.000280 -0.003493  0.006581  0.005990   \n",
       "7     0.000910 -0.000019 -0.003791  0.006280  0.005689 -0.009226   \n",
       "8    -0.001160 -0.003772  0.006299  0.005708 -0.009208  0.005334   \n",
       "9     0.009937  0.010109  0.009516 -0.005456  0.009141 -0.015605   \n",
       "10   -0.001175 -0.000588 -0.015410 -0.000959 -0.025457 -0.027624   \n",
       "11   -0.010514 -0.014831 -0.000371 -0.024884 -0.027052 -0.027194   \n",
       "12    0.013961  0.014677 -0.010205 -0.012405 -0.012550 -0.009606   \n",
       "13   -0.022231 -0.024522 -0.026691 -0.026833 -0.023931 -0.019831   \n",
       "14   -0.006267 -0.002223 -0.002369  0.000606  0.004809  0.004767   \n",
       "15   -0.001103 -0.000146  0.002835  0.007048  0.007006  0.004614   \n",
       "16    0.001632  0.002982  0.007195  0.007154  0.004761  0.002798   \n",
       "17    0.001892  0.004201  0.004159  0.001774 -0.000183  0.005044   \n",
       "18    0.002837 -0.000041 -0.002417 -0.004366  0.000839 -0.000741   \n",
       "19   -0.001026 -0.002376 -0.004325  0.000881 -0.000700 -0.002064   \n",
       "20   -0.002703 -0.001954  0.003264  0.001680  0.000313 -0.004929   \n",
       "21    0.004267  0.005228  0.003641  0.002271 -0.002981 -0.001035   \n",
       "22   -0.002257 -0.001579 -0.002942 -0.008167 -0.006231 -0.006791   \n",
       "23    0.000833 -0.001365 -0.006598 -0.004659 -0.005220 -0.006653   \n",
       "24   -0.005400 -0.005240 -0.003299 -0.003860 -0.005295 -0.003107   \n",
       "25   -0.001243  0.001952  0.001387 -0.000055  0.002145  0.004017   \n",
       "26    0.002856 -0.000563 -0.002003  0.000192  0.002061 -0.003429   \n",
       "27   -0.001218 -0.001440  0.000756  0.002626 -0.002867 -0.000082   \n",
       "28    0.001072  0.002200  0.004072 -0.001429  0.001360  0.000563   \n",
       "29    0.001864  0.001869 -0.003621 -0.000838 -0.001633  0.003094   \n",
       "...        ...       ...       ...       ...       ...       ...   \n",
       "5653 -0.008358 -0.008337 -0.008782 -0.008515 -0.011417 -0.016471   \n",
       "5654 -0.000246 -0.000448 -0.000179 -0.003106 -0.008202 -0.002058   \n",
       "5657 -0.004891 -0.005113  0.001051 -0.007341 -0.001071 -0.001606   \n",
       "5658  0.006061  0.006195 -0.002240  0.004062  0.003525  0.024948   \n",
       "5659 -0.008361 -0.008384 -0.002120 -0.002655  0.018637  0.002984   \n",
       "5660  0.006204  0.006316  0.005778  0.027249  0.011463  0.011963   \n",
       "5661 -0.000402 -0.000535  0.020801  0.005115  0.005611 -0.009790   \n",
       "5663 -0.014630 -0.015367 -0.014880 -0.029968 -0.045826 -0.047028   \n",
       "5664  0.000247  0.000494 -0.014829 -0.030935 -0.032155 -0.040013   \n",
       "5670 -0.000682 -0.000555  0.000000 -0.005350 -0.005012 -0.001875   \n",
       "5671  0.001046  0.000555 -0.004798 -0.004460 -0.001321  0.003833   \n",
       "5672 -0.005647 -0.005350 -0.005012 -0.001875  0.003276  0.002460   \n",
       "5674  0.003132  0.003153  0.008330  0.007510  0.009562  0.015089   \n",
       "5676 -0.000749 -0.000813  0.001222  0.006704 -0.000107  0.002426   \n",
       "5679 -0.006894 -0.006766 -0.004250 -0.006447 -0.001807  0.001922   \n",
       "5680  0.002447  0.002533  0.000321  0.004992  0.008747  0.004841   \n",
       "5681 -0.002099 -0.002206  0.002453  0.006199  0.002302  0.003101   \n",
       "5682  0.004691  0.004669  0.008423  0.004518  0.005318 -0.000492   \n",
       "5684 -0.003830 -0.003873 -0.003079 -0.008841 -0.006566 -0.002692   \n",
       "5686 -0.005972 -0.005780 -0.003497  0.000388 -0.013278 -0.014890   \n",
       "5687  0.002403  0.002296  0.006203 -0.007542 -0.009163 -0.001176   \n",
       "5689 -0.013428 -0.013661 -0.015272 -0.007334 -0.012927 -0.018042   \n",
       "5690 -0.001760 -0.001633  0.006415  0.000744 -0.004442 -0.003873   \n",
       "5691  0.008104  0.008061  0.002381 -0.002813 -0.002243  0.002616   \n",
       "5693 -0.005288 -0.005182 -0.004614  0.000234  0.000340  0.003007   \n",
       "5695  0.004891  0.004870  0.004977  0.007656 -0.000529  0.003121   \n",
       "5699  0.003736  0.003651  0.002141  0.006300 -0.016517 -0.019149   \n",
       "5703 -0.002656 -0.002676  0.002273 -0.001869  0.004199  0.007672   \n",
       "5704  0.004879  0.004962  0.000810  0.006894  0.010376  0.018597   \n",
       "5706  0.006058  0.006079  0.009559  0.017773  0.022700  0.020425   \n",
       "\n",
       "            ...          126d_Ret  189d_Ret  252d_Ret    1d_VIX    5d_VIX  \\\n",
       "0           ...          0.054196  0.044752  0.152477 -0.054198 -0.068421   \n",
       "1           ...          0.046503  0.050294  0.147818 -0.096552 -0.177136   \n",
       "2           ...          0.044326  0.041296  0.111197  0.179821 -0.066323   \n",
       "3           ...          0.062659  0.048637  0.120301  0.022463 -0.200390   \n",
       "4           ...          0.069373  0.067784  0.122976 -0.096241 -0.262577   \n",
       "5           ...          0.062066  0.070242  0.113438 -0.164573 -0.266814   \n",
       "6           ...          0.043887  0.066919  0.087846  0.025113 -0.108123   \n",
       "7           ...          0.042659  0.047618  0.092486  0.010410  0.024406   \n",
       "8           ...          0.043707  0.031880  0.074847 -0.057055 -0.121714   \n",
       "9           ...          0.052274  0.050822  0.076154 -0.101433  0.302958   \n",
       "10          ...          0.048613  0.051352  0.074658  0.016246  0.519263   \n",
       "11          ...          0.055106  0.056973  0.089087  0.177441  0.485025   \n",
       "12          ...          0.069022  0.052046  0.100961 -0.133714  0.265442   \n",
       "13          ...          0.052231  0.039163  0.089905  0.398881  0.298220   \n",
       "14          ...          0.096368  0.057041  0.123200  0.047739 -0.067809   \n",
       "15          ...          0.098982  0.052521  0.110058 -0.006656 -0.089939   \n",
       "16          ...          0.104696  0.045317  0.138069  0.003339 -0.071097   \n",
       "17          ...          0.089032  0.063602  0.117291 -0.111276 -0.122344   \n",
       "18          ...          0.085435  0.043929  0.113913  0.004471 -0.011005   \n",
       "19          ...          0.089069  0.032493  0.134337  0.022866 -0.002230   \n",
       "20          ...          0.095482  0.046005  0.103408  0.013910  0.059774   \n",
       "21          ...          0.102120  0.043189  0.096291 -0.052015  0.054605   \n",
       "22          ...          0.122558  0.038380  0.091253  0.001467  0.203704   \n",
       "23          ...          0.115202  0.039887  0.119536  0.013383  0.192476   \n",
       "24          ...          0.114639  0.042581  0.164826  0.086430  0.103363   \n",
       "25          ...          0.133226  0.046779  0.155128  0.008965 -0.020570   \n",
       "26          ...          0.136040  0.048721  0.107439  0.082011  0.038950   \n",
       "27          ...          0.122524  0.048134  0.072770 -0.007874 -0.018182   \n",
       "28          ...          0.140391  0.066610  0.051649 -0.062346 -0.021404   \n",
       "29          ...          0.137859  0.062844  0.040679 -0.035601  0.011618   \n",
       "...         ...               ...       ...       ...       ...       ...   \n",
       "5653        ...         -0.055481 -0.010843 -0.005931  0.077597  0.036725   \n",
       "5654        ...         -0.049670  0.000336 -0.002861 -0.017824 -0.055556   \n",
       "5657        ...         -0.029385 -0.005577 -0.002429 -0.011439 -0.094319   \n",
       "5658        ...         -0.023889  0.003972  0.001447 -0.018322 -0.304147   \n",
       "5659        ...         -0.028698 -0.004187 -0.002832 -0.003534 -0.172616   \n",
       "5660        ...         -0.018076  0.006182  0.020460 -0.023015 -0.086606   \n",
       "5661        ...         -0.027543 -0.001315  0.012016 -0.041368  0.053972   \n",
       "5663        ...         -0.048598 -0.005686 -0.007619  0.167237  0.746159   \n",
       "5664        ...         -0.033624 -0.000157  0.009923  0.100054  0.522710   \n",
       "5670        ...          0.023594  0.049080  0.039168 -0.080657 -0.151620   \n",
       "5671        ...          0.027619  0.057786  0.046265 -0.066248 -0.094046   \n",
       "5672        ...          0.034419  0.050703  0.044077  0.076577 -0.136665   \n",
       "5674        ...          0.026306  0.061351  0.046026 -0.120606 -0.229003   \n",
       "5676        ...          0.011720  0.043761  0.041712 -0.110175 -0.089341   \n",
       "5679        ...          0.004721  0.037204  0.031278  0.148508  0.011614   \n",
       "5680        ...          0.020896  0.048678  0.029401 -0.112138 -0.103856   \n",
       "5681        ...          0.020212  0.045090  0.020928  0.138149  0.025268   \n",
       "5682        ...          0.018298  0.049920  0.027531 -0.108750 -0.041022   \n",
       "5684        ...          0.003707  0.028774  0.037883  0.017413  0.025063   \n",
       "5686        ...          0.001898  0.023334  0.033789  0.064560  0.170858   \n",
       "5687        ...          0.011344  0.029328  0.042956  0.004730  0.011565   \n",
       "5689        ...          0.006984  0.026193  0.047093  0.147376  0.215537   \n",
       "5690        ...          0.022950  0.038043  0.064091  0.028846  0.038060   \n",
       "5691        ...          0.025426  0.050373  0.069386 -0.080272 -0.053221   \n",
       "5693        ...          0.031086  0.054952  0.080645  0.050267 -0.031601   \n",
       "5695        ...          0.036137  0.055745  0.094050 -0.061625 -0.019034   \n",
       "5699        ...          0.053034  0.076361  0.056092 -0.026354  0.253534   \n",
       "5703        ...          0.071387  0.086817  0.070791  0.013195  0.043689   \n",
       "5704        ...          0.075581  0.087398  0.072159 -0.003756 -0.050134   \n",
       "5706        ...          0.071983  0.084585  0.088261  0.069416 -0.083621   \n",
       "\n",
       "      1d_Rel_Vol  5d_Rel_Vol    1d_PtT  1d_VIX_PtT  Intraday_Increase  \n",
       "0       0.150982   -0.002956  0.009513    0.105180                  0  \n",
       "1      -0.003421   -0.000493  0.009094    0.135299                  1  \n",
       "2      -0.062535   -0.016959  0.006272    0.098703                  1  \n",
       "3      -0.022102   -0.021904  0.004509    0.053520                  0  \n",
       "4      -0.054481    0.101086  0.004163    0.128296                  0  \n",
       "5       0.010656    0.093209  0.011858    0.188227                  1  \n",
       "6      -0.174317    0.099463  0.005427    0.090615                  1  \n",
       "7      -0.218716    0.178595  0.008265    0.088686                  0  \n",
       "8       0.320440    0.240760  0.007131    0.114537                  0  \n",
       "9      -0.159209    0.210159  0.013551    0.135979                  0  \n",
       "10     -0.090453    0.239457  0.010076    0.100643                  1  \n",
       "11      0.083377    0.217709  0.014120    0.185634                  0  \n",
       "12      0.089148    0.170459  0.020645    0.325871                  0  \n",
       "13      0.246563    0.102898  0.019209    0.334444                  1  \n",
       "14      0.125359    0.044724  0.003414    0.078351                  0  \n",
       "15     -0.030634    0.045834  0.004026    0.057071                  0  \n",
       "16      0.040295    0.019176  0.005252    0.088380                  1  \n",
       "17     -0.035539   -0.048334  0.005177    0.157171                  1  \n",
       "18      0.062502   -0.037720  0.007586    0.122034                  1  \n",
       "19      0.258270   -0.076330  0.005727    0.103163                  0  \n",
       "20     -0.007223   -0.116234  0.005446    0.069071                  0  \n",
       "21     -0.150567   -0.114401  0.006110    0.113208                  0  \n",
       "22      0.120028   -0.110269  0.012684    0.205958                  1  \n",
       "23     -0.014510   -0.129540  0.004262    0.058716                  0  \n",
       "24      0.031850   -0.109254  0.007068    0.130784                  0  \n",
       "25     -0.030742   -0.090006  0.003026    0.058704                  0  \n",
       "26     -0.143437   -0.078570  0.004212    0.087097                  0  \n",
       "27     -0.048225   -0.061536  0.004519    0.082573                  1  \n",
       "28      0.042464   -0.072460  0.003008    0.093948                  0  \n",
       "29      0.067478   -0.066361  0.006688    0.126817                  1  \n",
       "...          ...         ...       ...         ...                ...  \n",
       "5653   -0.031070   -0.100699  0.014380    0.114114                  0  \n",
       "5654    0.174395   -0.135747  0.004571    0.073604                  0  \n",
       "5657   -0.060616   -0.145316  0.007733    0.073512                  0  \n",
       "5658   -0.203576   -0.069716  0.007224    0.074298                  0  \n",
       "5659   -0.188452    0.002549  0.011982    0.069420                  1  \n",
       "5660   -0.182802    0.098977  0.010501    0.077937                  0  \n",
       "5661   -0.197065    0.179804  0.010376    0.090006                  1  \n",
       "5663   -0.006670    0.139560  0.022157    0.197557                  1  \n",
       "5664    0.309400    0.061666  0.024682    0.180745                  0  \n",
       "5670   -0.131032    0.033622  0.003968    0.097561                  0  \n",
       "5671   -0.145498    0.058090  0.005527    0.089279                  0  \n",
       "5672   -0.281686    0.087666  0.008152    0.053398                  1  \n",
       "5674    0.034277   -0.024682  0.005168    0.043863                  1  \n",
       "5676   -0.022699    0.021934  0.006314    0.095661                  1  \n",
       "5679    0.225758    0.019406  0.010376    0.052099                  1  \n",
       "5680    0.043711   -0.035383  0.008617    0.044689                  0  \n",
       "5681   -0.046323    0.003573  0.005939    0.019814                  1  \n",
       "5682   -0.099951    0.006332  0.007149    0.208617                  0  \n",
       "5684   -0.033768   -0.045316  0.005023    0.052550                  1  \n",
       "5686    0.018892   -0.041025  0.011614    0.316790                  1  \n",
       "5687   -0.102444   -0.073126  0.006622    0.090361                  0  \n",
       "5689    0.129904   -0.013984  0.013670    0.097143                  1  \n",
       "5690    0.033386   -0.045985  0.006241    0.169887                  0  \n",
       "5691   -0.122932   -0.037410  0.008667    0.115911                  0  \n",
       "5693    0.260339   -0.107507  0.014166    0.131123                  0  \n",
       "5695    0.079439   -0.086152  0.006746    0.054446                  1  \n",
       "5699   -0.023841    0.065915  0.005001    0.086990                  0  \n",
       "5703   -0.010936    0.061150  0.006752    0.058934                  0  \n",
       "5704    0.008291    0.092981  0.005532    0.046336                  0  \n",
       "5706    0.000821    0.125499  0.008643    0.115310                  0  \n",
       "\n",
       "[2678 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split features and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intraday_Increase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2678.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.547050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.497874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Intraday_Increase\n",
       "count        2678.000000\n",
       "mean            0.547050\n",
       "std             0.497874\n",
       "min             0.000000\n",
       "25%             0.000000\n",
       "50%             1.000000\n",
       "75%             1.000000\n",
       "max             1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = dataset.drop('Intraday_Increase', axis=1)\n",
    "y = pd.DataFrame(dataset['Intraday_Increase'])\n",
    "\n",
    "# Summarize the label data\n",
    "display(y.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scale features (mean = 0, stdev = 1):\n",
    "X_scaled = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2678.000000</td>\n",
       "      <td>2678.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.452950</td>\n",
       "      <td>0.547050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.497874</td>\n",
       "      <td>0.497874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1\n",
       "count  2678.000000  2678.000000\n",
       "mean      0.452950     0.547050\n",
       "std       0.497874     0.497874\n",
       "min       0.000000     0.000000\n",
       "25%       0.000000     0.000000\n",
       "50%       0.000000     1.000000\n",
       "75%       1.000000     1.000000\n",
       "max       1.000000     1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2678, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1-hot encoding on labels (y):\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(y)\n",
    "y_scaled = enc.transform(y).toarray()\n",
    "\n",
    "y_insight = pd.DataFrame(y_scaled)\n",
    "\n",
    "display(y_insight.describe())\n",
    "\n",
    "y_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train, validation and test sets: Shuffling will not be used because test data should be drawn from the latest data points, to remove any risk of the learning algorithms glimpsing the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (1922, 21) (1922, 2)\n",
      "Validation set (504, 21) (504, 2)\n",
      "Test set (252, 21) (252, 2)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = X_scaled[756:]\n",
    "valid_dataset = X_scaled[252:756]\n",
    "test_dataset = X_scaled[:252]\n",
    "\n",
    "train_labels = y_scaled[756:]\n",
    "valid_labels = y_scaled[252:756]\n",
    "test_labels = y_scaled[:252]\n",
    "\n",
    "tf.cast(train_dataset, tf.float32)\n",
    "tf.cast(valid_dataset, tf.float32)\n",
    "tf.cast(test_dataset, tf.float32)\n",
    "\n",
    "tf.cast(train_labels, tf.float32)\n",
    "tf.cast(valid_labels, tf.float32)\n",
    "tf.cast(test_labels, tf.float32)\n",
    "\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)\n",
    "\n",
    "describe_train = pd.DataFrame(train_dataset)\n",
    "describe_valid = pd.DataFrame(valid_dataset)\n",
    "describe_test = pd.DataFrame(test_dataset)\n",
    "\n",
    "describe_train_labels = pd.DataFrame(train_labels)\n",
    "describe_valid_labels = pd.DataFrame(valid_labels)\n",
    "describe_test_labels = pd.DataFrame(test_labels)\n",
    "\n",
    "\n",
    "#display(describe_train.describe())\n",
    "#display(describe_valid.describe())\n",
    "#display(describe_test.describe())\n",
    "\n",
    "#display(describe_train_labels.describe())\n",
    "#display(describe_valid_labels.describe())\n",
    "#display(describe_test_labels.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics\n",
    "\n",
    "Accuracy and F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "def F1_score(predictions, labels):\n",
    "  return f1_score(np.argmax(labels, 1), np.argmax(predictions, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create TensorFlow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1921\n",
    "num_labels = 2\n",
    "num_features = 21\n",
    "\n",
    "# Add second and third hidden layer, each with fewer nodes:\n",
    "\n",
    "num_nodes1 = 16\n",
    "num_nodes2 = 8\n",
    "num_nodes3 = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  tf.set_random_seed(8)\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, num_features))\n",
    "    \n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  \n",
    "  tf_valid_dataset = tf.constant(valid_dataset,tf.float32)\n",
    "  tf_test_dataset = tf.constant(test_dataset,tf.float32)\n",
    "  \n",
    "  # Variables.\n",
    "  weights_1 = tf.Variable(tf.truncated_normal([num_features, num_nodes1],stddev=0.22))\n",
    "  biases_1 = tf.Variable(tf.zeros([num_nodes1]))\n",
    "  \n",
    "  weights_2 = tf.Variable(tf.truncated_normal([num_nodes1, num_nodes2],stddev=0.32))\n",
    "  biases_2 = tf.Variable(tf.zeros([num_nodes2]))\n",
    "\n",
    "  weights_3 = tf.Variable(tf.truncated_normal([num_nodes2, num_nodes3],stddev=0.45))\n",
    "  biases_3 = tf.Variable(tf.zeros([num_nodes3]))\n",
    "\n",
    "  weights_4 = tf.Variable(tf.truncated_normal([num_nodes3, num_labels],stddev=0.71))\n",
    "  biases_4 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "  # Training computation - Layer 1\n",
    "  hidden1 = tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1)\n",
    "  \n",
    "  # Adding Dropout - Layer 1\n",
    "  keep_prob1 = tf.placeholder(tf.float32)\n",
    "  hidden1_drop = tf.nn.dropout(hidden1,keep_prob1)\n",
    "    \n",
    "  # Training computation - Layer 2\n",
    "  hidden2 = tf.nn.relu(tf.matmul(hidden1_drop, weights_2) + biases_2)\n",
    "  \n",
    "  # Adding Dropout - Layer 2\n",
    "  keep_prob2 = tf.placeholder(tf.float32)\n",
    "  hidden2_drop = tf.nn.dropout(hidden2,keep_prob2)\n",
    "    \n",
    "  # Training computation - Layer 3 \n",
    "  hidden3 = tf.nn.relu(tf.matmul(hidden2_drop, weights_3) + biases_3)\n",
    "  \n",
    "  # Adding Dropout - Layer 3\n",
    "  keep_prob3 = tf.placeholder(tf.float32)\n",
    "  hidden3_drop = tf.nn.dropout(hidden3,keep_prob3)\n",
    "    \n",
    "  logits = tf.matmul(hidden3_drop, weights_4) + biases_4\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = tf_train_labels))\n",
    "    \n",
    "  # L2 regularization for the fully connected parameters.\n",
    "  regularizers = (tf.nn.l2_loss(weights_1) + tf.nn.l2_loss(biases_1) +\n",
    "                  tf.nn.l2_loss(weights_2) + tf.nn.l2_loss(biases_2) +\n",
    "                  tf.nn.l2_loss(weights_3) + tf.nn.l2_loss(biases_3) +\n",
    "                  tf.nn.l2_loss(weights_4) + tf.nn.l2_loss(biases_4))\n",
    "    \n",
    "  # Add the regularization term to the loss.\n",
    "  loss += 1e-6 * regularizers    \n",
    "  \n",
    "  # Optimizer - Add learning rate decay\n",
    "  global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "  learning_rate = tf.train.exponential_decay(\n",
    "        0.05, global_step, 100000, 0.98, staircase=True)\n",
    "    \n",
    "  optimizer = tf.train.GradientDescentOptimizer(\n",
    "    learning_rate).minimize(loss, global_step=global_step)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  \n",
    "  valid_prediction = tf.nn.softmax(\n",
    "        tf.matmul(tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(tf_valid_dataset, weights_1)+\n",
    "                                                                       biases_1), weights_2)+ biases_2), weights_3)\n",
    "                             + biases_3), weights_4)+ biases_4)\n",
    "\n",
    "  test_prediction = tf.nn.softmax(\n",
    "        tf.matmul(tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(tf_test_dataset, weights_1)+\n",
    "                                                                       biases_1), weights_2)+ biases_2), weights_3)\n",
    "                             + biases_3), weights_4)+ biases_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set restricted to the following number of samples: 1921\n",
      "Training set (1921, 21) (1921, 2)\n",
      "Initialized\n",
      "Minibatch loss at step 0: 0.701603\n",
      "Minibatch accuracy: 53.2%\n",
      "Validation accuracy: 52.4%\n",
      "Test accuracy: 52.78%\n",
      "F1 Score: 0.690909\n",
      "Minibatch loss at step 500: 0.666171\n",
      "Minibatch accuracy: 59.8%\n",
      "Validation accuracy: 57.9%\n",
      "Test accuracy: 58.73%\n",
      "F1 Score: 0.695906\n",
      "Minibatch loss at step 1000: 0.642354\n",
      "Minibatch accuracy: 64.3%\n",
      "Validation accuracy: 61.9%\n",
      "Test accuracy: 62.30%\n",
      "F1 Score: 0.677966\n",
      "Minibatch loss at step 1500: 0.640639\n",
      "Minibatch accuracy: 63.6%\n",
      "Validation accuracy: 62.9%\n",
      "Test accuracy: 63.89%\n",
      "F1 Score: 0.689420\n",
      "Minibatch loss at step 2000: 0.631733\n",
      "Minibatch accuracy: 64.2%\n",
      "Validation accuracy: 63.7%\n",
      "Test accuracy: 63.10%\n",
      "F1 Score: 0.682594\n",
      "Minibatch loss at step 2500: 0.621189\n",
      "Minibatch accuracy: 65.5%\n",
      "Validation accuracy: 63.3%\n",
      "Test accuracy: 63.89%\n",
      "F1 Score: 0.678445\n",
      "Minibatch loss at step 3000: 0.606341\n",
      "Minibatch accuracy: 66.5%\n",
      "Validation accuracy: 63.5%\n",
      "Test accuracy: 63.89%\n",
      "F1 Score: 0.673835\n",
      "Minibatch loss at step 3500: 0.601227\n",
      "Minibatch accuracy: 67.4%\n",
      "Validation accuracy: 62.5%\n",
      "Test accuracy: 63.10%\n",
      "F1 Score: 0.666667\n",
      "Minibatch loss at step 4000: 0.591945\n",
      "Minibatch accuracy: 68.5%\n",
      "Validation accuracy: 63.3%\n",
      "Test accuracy: 63.49%\n",
      "F1 Score: 0.669065\n",
      "Minibatch loss at step 4500: 0.595803\n",
      "Minibatch accuracy: 67.8%\n",
      "Validation accuracy: 62.1%\n",
      "Test accuracy: 63.89%\n",
      "F1 Score: 0.666667\n",
      "Minibatch loss at step 5000: 0.586439\n",
      "Minibatch accuracy: 69.3%\n",
      "Validation accuracy: 61.7%\n",
      "Test accuracy: 61.51%\n",
      "F1 Score: 0.639405\n",
      "Minibatch loss at step 5500: 0.576067\n",
      "Minibatch accuracy: 69.7%\n",
      "Validation accuracy: 61.7%\n",
      "Test accuracy: 62.30%\n",
      "F1 Score: 0.646840\n",
      "Minibatch loss at step 6000: 0.575043\n",
      "Minibatch accuracy: 70.0%\n",
      "Validation accuracy: 61.1%\n",
      "Test accuracy: 61.90%\n",
      "F1 Score: 0.641791\n",
      "Minibatch loss at step 6500: 0.568027\n",
      "Minibatch accuracy: 70.5%\n",
      "Validation accuracy: 60.7%\n",
      "Test accuracy: 60.71%\n",
      "F1 Score: 0.626415\n",
      "Minibatch loss at step 7000: 0.560777\n",
      "Minibatch accuracy: 70.6%\n",
      "Validation accuracy: 60.5%\n",
      "Test accuracy: 61.51%\n",
      "F1 Score: 0.631179\n",
      "Minibatch loss at step 7500: 0.561565\n",
      "Minibatch accuracy: 70.6%\n",
      "Validation accuracy: 60.7%\n",
      "Test accuracy: 62.70%\n",
      "F1 Score: 0.641221\n",
      "Minibatch loss at step 8000: 0.553795\n",
      "Minibatch accuracy: 72.5%\n",
      "Validation accuracy: 60.9%\n",
      "Test accuracy: 60.71%\n",
      "F1 Score: 0.617761\n",
      "Minibatch loss at step 8500: 0.548813\n",
      "Minibatch accuracy: 73.1%\n",
      "Validation accuracy: 60.3%\n",
      "Test accuracy: 61.11%\n",
      "F1 Score: 0.623077\n",
      "Minibatch loss at step 9000: 0.534758\n",
      "Minibatch accuracy: 73.9%\n",
      "Validation accuracy: 60.3%\n",
      "Test accuracy: 61.51%\n",
      "F1 Score: 0.628352\n",
      "Minibatch loss at step 9500: 0.538827\n",
      "Minibatch accuracy: 73.3%\n",
      "Validation accuracy: 60.9%\n",
      "Test accuracy: 61.90%\n",
      "F1 Score: 0.630769\n",
      "Minibatch loss at step 10000: 0.547423\n",
      "Minibatch accuracy: 73.2%\n",
      "Validation accuracy: 60.3%\n",
      "Test accuracy: 61.90%\n",
      "F1 Score: 0.633588\n",
      "\n",
      "\n",
      "FINAL Test accuracy: 61.90%\n",
      "FINAL F1 Score: 0.633588\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10001\n",
    "\n",
    "# Set train_batches to 8 to use the full training set\n",
    "train_batches = 1\n",
    "train_subset = train_batches * batch_size\n",
    "\n",
    "print('Training set restricted to the following number of samples:',train_subset)\n",
    "\n",
    "train_smallset = train_dataset[0:train_subset,:]\n",
    "train_smalllabel = train_labels[0:train_subset]\n",
    "\n",
    "print('Training set', train_smallset.shape, train_smalllabel.shape)\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "\n",
    "  print(\"Initialized\")\n",
    "    \n",
    "  step_counter = []\n",
    "  step_train_accuracy = []\n",
    "  step_valid_accuracy = []\n",
    "  step_test_accuracy = []\n",
    "    \n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "#    offset = (step * batch_size) % (train_smalllabel.shape[0] - batch_size)\n",
    "    offset = 0\n",
    "\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_smallset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_smalllabel[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels,keep_prob1: 0.95,\n",
    "                 keep_prob2:0.95,keep_prob3:0.95}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    \n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "      print(\"Test accuracy: %.2f%%\" % accuracy(test_prediction.eval(), test_labels))   \n",
    "      print (\"F1 Score: %f\" % F1_score(test_prediction.eval(), test_labels))\n",
    "      \n",
    "      step_counter.append(step)\n",
    "      step_train_accuracy.append(accuracy(predictions, batch_labels))\n",
    "      step_valid_accuracy.append(accuracy(valid_prediction.eval(), valid_labels))\n",
    "      step_test_accuracy.append(accuracy(test_prediction.eval(), test_labels))\n",
    "    \n",
    "  print('\\n')\n",
    "  print(\"FINAL Test accuracy: %.2f%%\" % accuracy(test_prediction.eval(), test_labels))   \n",
    "  print (\"FINAL F1 Score: %f\" % F1_score(test_prediction.eval(), test_labels))\n",
    "\n",
    "  saver = tf.train.Saver()\n",
    "  saver.save(session, 'data/NN.model')\n",
    "  \n",
    "  np.savetxt(\"data/eval-NN.csv\", test_prediction.eval(), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1154d9fd0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11446a470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(step_train_accuracy, label = 'train')\n",
    "plt.plot(step_valid_accuracy, label = 'validate')\n",
    "plt.plot(step_test_accuracy, label = 'test')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('Number of 500 Step Training Batches')\n",
    "plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
